{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>olor intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>isTrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        1       13.20  1.78               2.14       11.2            100   \n",
       "1        1       13.16  2.36               2.67       18.6            101   \n",
       "2        1       14.37  1.95               2.50       16.8            113   \n",
       "3        1       13.24  2.59               2.87       21.0            118   \n",
       "4        1       14.20  1.76               2.45       15.2            112   \n",
       "5        1       14.39  1.87               2.45       14.6             96   \n",
       "6        1       14.06  2.15               2.61       17.6            121   \n",
       "7        1       14.83  1.64               2.17       14.0             97   \n",
       "8        1       13.86  1.35               2.27       16.0             98   \n",
       "9        1       14.10  2.16               2.30       18.0            105   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  olor intensity   Hue  \\\n",
       "0        2.65                  2.76             0.26            1.28  4.38   \n",
       "1        2.80                  3.24             0.30            2.81  5.68   \n",
       "2        3.85                  3.49             0.24            2.18  7.80   \n",
       "3        2.80                  2.69             0.39            1.82  4.32   \n",
       "4        3.27                  3.39             0.34            1.97  6.75   \n",
       "5        2.50                  2.52             0.30            1.98  5.25   \n",
       "6        2.60                  2.51             0.31            1.25  5.05   \n",
       "7        2.80                  2.98             0.29            1.98  5.20   \n",
       "8        2.98                  3.15             0.22            1.85  7.22   \n",
       "9        2.95                  3.32             0.22            2.38  5.75   \n",
       "\n",
       "   OD280  Proline  isTrain  \n",
       "0   1.05     3.40     True  \n",
       "1   1.03     3.17    False  \n",
       "2   0.86     3.45     True  \n",
       "3   1.04     2.93    False  \n",
       "4   1.05     2.85    False  \n",
       "5   1.02     3.58    False  \n",
       "6   1.06     3.58    False  \n",
       "7   1.08     2.85     True  \n",
       "8   1.01     3.55     True  \n",
       "9   1.25     3.17     True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import operator\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "os.path.isfile('/Users/16786/Desktop/wine.data')\n",
    "\n",
    "df= pd.read_csv('/Users/16786/Desktop/wine.data')\n",
    "df.columns = [ 'Alcohol', 'Malic acid', 'Ash', 'alcalinity of ash', 'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
    "'Proanthocyanins', 'olor intensity', 'Hue', 'OD280', 'Proline', 'isTrain']\n",
    "#df.columns = ['sepal length', 'sepal width', ' petal length', 'petal width', 'FlowerClass']\n",
    "#seperate aproximently 25% out to be in the test set with which sample goes in each set being random\n",
    "df['isTrain'] = np.random.uniform(0,1,len(df)) <= .75\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set 134\n",
      "length of test set 43\n",
      "11.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>olor intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>isTrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0        0       13.20  1.78               2.14       11.2            100   \n",
       "1        0       13.16  2.36               2.67       18.6            101   \n",
       "2        0       14.37  1.95               2.50       16.8            113   \n",
       "3        0       13.24  2.59               2.87       21.0            118   \n",
       "4        0       14.20  1.76               2.45       15.2            112   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  olor intensity   Hue  \\\n",
       "0        2.65                  2.76             0.26            1.28  4.38   \n",
       "1        2.80                  3.24             0.30            2.81  5.68   \n",
       "2        3.85                  3.49             0.24            2.18  7.80   \n",
       "3        2.80                  2.69             0.39            1.82  4.32   \n",
       "4        3.27                  3.39             0.34            1.97  6.75   \n",
       "\n",
       "   OD280  Proline  isTrain  \n",
       "0   1.05     3.40     True  \n",
       "1   1.03     3.17    False  \n",
       "2   0.86     3.45     True  \n",
       "3   1.04     2.93    False  \n",
       "4   1.05     2.85    False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adjusting the alcohol classes to start at 0 instead of 1.\n",
    "for x in range (0,len(df)):\n",
    "    if df.iloc[x,0] == 1: \n",
    "        df.iloc[x,0] = 0\n",
    "    if df.iloc[x,0] == 2: \n",
    "        df.iloc[x,0] = 1\n",
    "    if df.iloc[x,0] == 3: \n",
    "        df.iloc[x,0] = 2\n",
    "#df.head(100)\n",
    "#seperating train and test into two different dataframes for time effecency \n",
    "train, test = df[df['isTrain']==True], df[df['isTrain']==False]\n",
    "#lengths of each set this will change with every run\n",
    "print('length of train set ' + str(len(train)))\n",
    "print('length of test set '+ str(len(test)))\n",
    "print((train[0:0+1]).iloc[0,4])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple euclidian distance function feed in two dataframe rows to compare and the lenght of each feature set,\n",
    "#output the euclidean distance between the two rows of features\n",
    "def euclidean_distance(a, b, length):\n",
    "    dist = 0\n",
    "    for x in range (1, length-1):\n",
    "        dist += pow((a.iloc[0,x] - b.iloc[0,x]), 2)\n",
    "        \n",
    "    return math.sqrt(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds the k nearest neigbors to a test set entry. inputs, the full training set, one row of test features, the number of neigbors being found\n",
    "#output a list containing the class of the k nearest neighbors to the test entry\n",
    "def get_k_nearest_neibors(training_set, test_entry, k):\n",
    "    dist_set = []\n",
    "    niegbors = []\n",
    "    \n",
    "    for x in range (1, len(train)-1):\n",
    "         #find Euclidean_distance\n",
    "        this_dist = euclidean_distance(train[x:x+1], test_entry, 13)\n",
    "        #pair that euclidean distance with the class value of the test point it came from\n",
    "        dist_set.append((this_dist, training_set[x:x+1].iloc[0,0]))\n",
    "    dist_set.sort(key=operator.itemgetter(0))\n",
    "    for n in range (0, k):\n",
    "        #add k niegbors value to the output\n",
    "         niegbors.append(dist_set[n][1])\n",
    "    #print(niegbors)\n",
    "    return niegbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calulates the accuracy by comparing a list of the predicted classes with a list of the true classes\n",
    "#output a sum of the number of correctly identifyed  classes\n",
    "def accuracy_calc(predicted, real):\n",
    "    correct = 0\n",
    "    for x in range (0, len(real)):\n",
    "        if predicted[x] == real[x:x+1].iloc[0,0]:\n",
    "            correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_accuracys = []\n",
    "list_of_accuracys_train = []\n",
    "#populating a list with nonsence values\n",
    "for p in range (99):\n",
    "    list_of_accuracys.append(-1)\n",
    "    list_of_accuracys_train.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryConversion(a):\n",
    "    sum = 0\n",
    "    factor = 1\n",
    "    for x in range(0, 6):\n",
    "        sum += a[5-x] * factor\n",
    "        factor = factor * 2\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "a = [1,1,0,0,0,1]\n",
    "print(binaryConversion(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.627906976744186\n"
     ]
    }
   ],
   "source": [
    "test_set_classifications = [0]\n",
    "for x in range (0, len(test)-1):\n",
    "        test_set_classifications.append(-1)\n",
    "#takes 99 different values of k and uses them to preform knn on the test set. accuracys are then calculated and stored in list_of_accuracys.  \n",
    "iterations = 16\n",
    "populationSize = 16\n",
    "numberItems = 6\n",
    "class_list = [0,0,0]\n",
    "count = 0\n",
    "items = [0 for x in range(numberItems)]\n",
    "fitnessArray = [0 for x in range(populationSize)]\n",
    "maxCost = 0\n",
    "items = [0 for x in range(numberItems)]\n",
    "populationArray = [[0 for x in range(numberItems)] for y in range(populationSize)]\n",
    "#make n bit arrays each representing a k value ranging from 0 to 64 one will always be added when calculated to insure k is not 0 \n",
    "for i in range (0, populationSize):\n",
    "    for n in range(0, numberItems):\n",
    "        r = random.uniform(0, 1)\n",
    "        if(r <= .5):\n",
    "            populationArray[i][n] = 0\n",
    "        if(r >= .5):\n",
    "            populationArray[i][n] = 1\n",
    "for i in range(0, populationSize):\n",
    "    binp = binaryConversion(populationArray[i])                     \n",
    "    for x in range (0, len(test)-1):\n",
    "        nieg = []\n",
    "        nieg = get_k_nearest_neibors(train, test[x:x+1], binaryConversion(populationArray[i])+1)\n",
    "        for n in range(0, binaryConversion(populationArray[i])-1):\n",
    "            for m in range (0,3):\n",
    "                if nieg[n] == (m):\n",
    "                    class_list[m] += 1\n",
    "        test_set_classifications[x] = (class_list.index(max(class_list)))\n",
    "        #print(test_set_classifications[x])\n",
    "        class_list = [0,0,0]\n",
    "        count += 1\n",
    "    accuracy = accuracy_calc(test_set_classifications, test)  \n",
    "    fitnessArray[i] = accuracy/len(test)\n",
    "    #next is the crossover and determination of what samples get to stay in the population\n",
    "#the top 1/4 of predictions will get to stay in the population with the bottom 3/4 being crossed\n",
    "#the center point of the cross will be random\n",
    "stayNub = int(populationSize/4)\n",
    "numbNew = len(populationArray) - stayNub\n",
    "finalSack = [0 for x in range(populationSize)]\n",
    "a = [0 for x in range(stayNub)]\n",
    "for m in range(0, iterations):\n",
    "    for i in range(0, populationSize):\n",
    "        costA = 0\n",
    "        weightA = 0\n",
    "        binp = binaryConversion(populationArray[i])                     \n",
    "        fitnessArray[i] = costA\n",
    "        for x in range (0, len(test)-1):\n",
    "            nieg = []\n",
    "            nieg = get_k_nearest_neibors(train, test[x:x+1], binaryConversion(populationArray[i])+1)\n",
    "            for n in range(0, binaryConversion(populationArray[i])-1):\n",
    "                for m in range (0,3):\n",
    "                    if nieg[n] == (m):\n",
    "                        class_list[m] += 1\n",
    "            test_set_classifications[x] = (class_list.index(max(class_list)))\n",
    "            #print(test_set_classifications[x])\n",
    "            class_list = [0,0,0]\n",
    "            count += 1\n",
    "    accuracy = accuracy_calc(test_set_classifications, test)  \n",
    "    fitnessArray[i] = accuracy/len(test)\n",
    "    if(max(fitnessArray) > maxCost):\n",
    "        maxCost = max(fitnessArray)\n",
    "        finalSack = populationArray[fitnessArray.index(max(fitnessArray))]\n",
    "                #preserve the current best cost and items \n",
    "        items = populationArray[fitnessArray.index(max(fitnessArray))]\n",
    "    \n",
    "for i in range(0, stayNub):\n",
    "    a[i] = fitnessArray.index(max(fitnessArray))\n",
    "    fitnessArray[fitnessArray.index(max(fitnessArray))] = -1\n",
    "            \n",
    "    #preserve the current best cost and items \n",
    "    #do the crossover \n",
    "    #pick random point to swap from\n",
    "    r = int(random.uniform(1, numberItems-1))\n",
    "    temp1 = [0 for x in range(0, r)]\n",
    "    temp2 = [0 for x in range(r, numberItems)]\n",
    "    temp3 = [0 for x in range(0, r)]\n",
    "    temp4 = [0 for x in range(r, numberItems)]\n",
    "    temp5 = [0 for x in range(0, len(a))]\n",
    "for i in range(0, len(a)):\n",
    "    temp5[i] = populationArray[a[i]]\n",
    "for i in range(0, populationSize-1):\n",
    "    r1 = int(random.uniform(0, numberItems-1))\n",
    "    r2 = r1+1\n",
    "    temp1 = populationArray[r1][0:r]\n",
    "    temp2 = populationArray[r2][r:len(populationArray)]\n",
    "    temp3 = populationArray[r1][0:r]\n",
    "    temp4 = populationArray[r2][r:len(populationArray)]\n",
    "        \n",
    "    populationArray[i] = temp1+temp4\n",
    "for i in range(0, len(a)):\n",
    "    populationArray[a[i]] = temp5[i]\n",
    "        \n",
    "# preform mutations\n",
    "for i in range(0, populationSize):\n",
    "    for n in range(0, numberItems):\n",
    "        r = random.uniform(0, 1)\n",
    "        if(r <= .1):\n",
    "            k = populationArray[i][n]\n",
    "            if(k == 1):\n",
    "                populationArray[i][n] = 0\n",
    "            if(k == 0):\n",
    "                populationArray[i][n] = 1\n",
    "print(maxCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1_to_49 = []\n",
    "print(list_of_accuracys)\n",
    "for x in range (0,99):\n",
    "    list_1_to_49.append(x+1)\n",
    "     #A graph showing the results of the test set accuracy of the first 99 k values\n",
    "plt.plot(list_1_to_49, list_of_accuracys)    \n",
    "plt.xlabel('k value') \n",
    "# naming the y axis \n",
    "plt.ylabel('accuracy') \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the preformance of train set on train set to test for over under fit\n",
    "\n",
    "test_set_classifications_train = [0]\n",
    "for x in range (0, len(train)-1):\n",
    "        test_set_classifications_train.append(-1)\n",
    "    #this part functions the same as the test set function above except its testing the training set on its self.\n",
    "for k in range (1,100):\n",
    "    \n",
    "    class_list = [0,0,0]\n",
    "    count = 0\n",
    "    for x in range (0, len(train)-1):\n",
    "        nieg = []\n",
    "        nieg = get_k_nearest_neibors(train, train[x:x+1], k)\n",
    "        for n in range(0, k):\n",
    "            for m in range (0,3):\n",
    "                if nieg[n] == (m):\n",
    "                    class_list[m] += 1\n",
    "        test_set_classifications_train[x] = (class_list.index(max(class_list)))\n",
    "        \n",
    "        class_list = [0,0,0]\n",
    "        count += 1\n",
    "    #print(test_set_classifications_train)\n",
    "    list_of_accuracys_train[k-1] = accuracy_calc(test_set_classifications_train, train)\n",
    "    list_of_accuracys_train[k-1] = list_of_accuracys_train[k-1]/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9921875, 0.90625, 0.9140625, 0.8671875, 0.8671875, 0.84375, 0.8203125, 0.78125, 0.765625, 0.7734375, 0.75, 0.7578125, 0.7578125, 0.734375, 0.7578125, 0.7421875, 0.734375, 0.7109375, 0.7109375, 0.7109375, 0.703125, 0.6953125, 0.6484375, 0.6640625, 0.6796875, 0.6796875, 0.6640625, 0.6640625, 0.6484375, 0.6328125, 0.65625, 0.65625, 0.6484375, 0.6796875, 0.65625, 0.671875, 0.640625, 0.6328125, 0.625, 0.625, 0.6171875, 0.609375, 0.609375, 0.578125, 0.5859375, 0.6015625, 0.6015625, 0.609375, 0.6171875, 0.609375, 0.6171875, 0.5859375, 0.5546875, 0.5703125, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.546875, 0.546875, 0.546875, 0.53125, 0.5390625, 0.515625, 0.4921875, 0.5, 0.5, 0.5234375, 0.53125, 0.53125, 0.5390625, 0.53125, 0.5234375, 0.5234375, 0.515625, 0.515625, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5, 0.5, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.484375, 0.4765625, 0.4765625, 0.484375, 0.484375, 0.484375, 0.4765625, 0.484375, 0.4765625]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(list_of_accuracys_train)\n",
    "plt.plot(list_1_to_49, list_of_accuracys_train, label = 'training data')\n",
    "plt.plot(list_1_to_49, list_of_accuracys, label = 'testing data')\n",
    "plt.xlabel('k value') \n",
    "# naming the y axis \n",
    "# A table comparing the test and training set accuracys,it show that a k value of around 5 is the most optimal.\n",
    "plt.ylabel('accuracy') \n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9921875, 0.90625, 0.9140625, 0.8671875, 0.8671875, 0.84375, 0.8203125, 0.78125, 0.765625, 0.7734375, 0.75, 0.7578125, 0.7578125, 0.734375, 0.7578125, 0.7421875, 0.734375, 0.7109375, 0.7109375, 0.7109375, 0.703125, 0.6953125, 0.6484375, 0.6640625, 0.6796875, 0.6796875, 0.6640625, 0.6640625, 0.6484375, 0.6328125, 0.65625, 0.65625, 0.6484375, 0.6796875, 0.65625, 0.671875, 0.640625, 0.6328125, 0.625, 0.625, 0.6171875, 0.609375, 0.609375, 0.578125, 0.5859375, 0.6015625, 0.6015625, 0.609375, 0.6171875, 0.609375, 0.6171875, 0.5859375, 0.5546875, 0.5703125, 0.5625, 0.5625, 0.5703125, 0.5703125, 0.546875, 0.546875, 0.546875, 0.53125, 0.5390625, 0.515625, 0.4921875, 0.5, 0.5, 0.5234375, 0.53125, 0.53125, 0.5390625, 0.53125, 0.5234375, 0.5234375, 0.515625, 0.515625, 0.5078125, 0.515625, 0.5078125, 0.5078125, 0.5078125, 0.5078125, 0.515625, 0.5, 0.5, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.4921875, 0.484375, 0.4765625, 0.4765625, 0.484375, 0.484375, 0.484375, 0.4765625, 0.484375, 0.4765625]\n"
     ]
    }
   ],
   "source": [
    "print(list_of_accuracys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
